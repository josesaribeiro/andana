[2019-01-21 22:03:34,322] {logging_mixin.py:95} INFO - Sending to executor.
[2019-01-21 22:03:34,323] {logging_mixin.py:95} INFO - [2019-01-21 22:03:34,322] {base_executor.py:56} INFO - Adding to queue: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:03:34,326] {logging_mixin.py:95} INFO - [2019-01-21 22:03:34,326] {sequential_executor.py:45} INFO - Executing command: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:03:35,397] {models.py:1355} INFO - Dependencies not met for <TaskInstance: seashells.get_data 2019-01-21T00:00:00+00:00 [None]>, dependency 'Trigger Rule' FAILED: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es). upstream_tasks_state={'total': 1, 'successes': 0, 'skipped': 0, 'failed': 0, 'upstream_failed': 0, 'done': 0}, upstream_task_ids={'set_path'}
[2019-01-21 22:03:35,398] {logging_mixin.py:95} INFO - [2019-01-21 22:03:35,398] {jobs.py:2614} INFO - Task is not able to be run
[2019-01-21 22:04:09,006] {logging_mixin.py:95} INFO - Sending to executor.
[2019-01-21 22:04:09,007] {logging_mixin.py:95} INFO - [2019-01-21 22:04:09,006] {base_executor.py:56} INFO - Adding to queue: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:04:09,010] {logging_mixin.py:95} INFO - [2019-01-21 22:04:09,010] {sequential_executor.py:45} INFO - Executing command: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:04:10,209] {models.py:1355} INFO - Dependencies not met for <TaskInstance: seashells.get_data 2019-01-21T00:00:00+00:00 [None]>, dependency 'Trigger Rule' FAILED: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es). upstream_tasks_state={'total': 1, 'successes': 0, 'skipped': 0, 'failed': 0, 'upstream_failed': 0, 'done': 0}, upstream_task_ids={'set_path'}
[2019-01-21 22:04:10,210] {logging_mixin.py:95} INFO - [2019-01-21 22:04:10,210] {jobs.py:2614} INFO - Task is not able to be run
[2019-01-21 22:10:45,732] {logging_mixin.py:95} INFO - Sending to executor.
[2019-01-21 22:10:45,733] {logging_mixin.py:95} INFO - [2019-01-21 22:10:45,732] {base_executor.py:56} INFO - Adding to queue: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:10:45,737] {logging_mixin.py:95} INFO - [2019-01-21 22:10:45,736] {sequential_executor.py:45} INFO - Executing command: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:10:46,746] {models.py:1355} INFO - Dependencies not met for <TaskInstance: seashells.get_data 2019-01-21T00:00:00+00:00 [None]>, dependency 'Trigger Rule' FAILED: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es). upstream_tasks_state={'total': 1, 'successes': 0, 'skipped': 0, 'failed': 0, 'upstream_failed': 0, 'done': 0}, upstream_task_ids={'set_path'}
[2019-01-21 22:10:46,747] {logging_mixin.py:95} INFO - [2019-01-21 22:10:46,747] {jobs.py:2614} INFO - Task is not able to be run
[2019-01-21 22:11:05,886] {logging_mixin.py:95} INFO - Sending to executor.
[2019-01-21 22:11:05,887] {logging_mixin.py:95} INFO - [2019-01-21 22:11:05,886] {base_executor.py:56} INFO - Adding to queue: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:11:05,890] {logging_mixin.py:95} INFO - [2019-01-21 22:11:05,889] {sequential_executor.py:45} INFO - Executing command: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:11:06,885] {models.py:1355} INFO - Dependencies not met for <TaskInstance: seashells.get_data 2019-01-21T00:00:00+00:00 [None]>, dependency 'Trigger Rule' FAILED: Task's trigger rule 'all_success' requires all upstream tasks to have succeeded, but found 1 non-success(es). upstream_tasks_state={'total': 1, 'successes': 0, 'skipped': 0, 'failed': 0, 'upstream_failed': 0, 'done': 0}, upstream_task_ids={'set_path'}
[2019-01-21 22:11:06,886] {logging_mixin.py:95} INFO - [2019-01-21 22:11:06,886] {jobs.py:2614} INFO - Task is not able to be run
[2019-01-21 22:13:36,854] {logging_mixin.py:95} INFO - Sending to executor.
[2019-01-21 22:13:36,855] {logging_mixin.py:95} INFO - [2019-01-21 22:13:36,855] {base_executor.py:56} INFO - Adding to queue: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:13:36,859] {logging_mixin.py:95} INFO - [2019-01-21 22:13:36,859] {sequential_executor.py:45} INFO - Executing command: airflow run seashells get_data 2019-01-21T00:00:00+00:00 --local -sd DAGS_FOLDER/tom_test.py
[2019-01-21 22:13:38,002] {models.py:1361} INFO - Dependencies all met for <TaskInstance: seashells.get_data 2019-01-21T00:00:00+00:00 [None]>
[2019-01-21 22:13:38,004] {models.py:1361} INFO - Dependencies all met for <TaskInstance: seashells.get_data 2019-01-21T00:00:00+00:00 [None]>
[2019-01-21 22:13:38,005] {models.py:1573} INFO - 
--------------------------------------------------------------------------------
Starting attempt 1 of 4
--------------------------------------------------------------------------------

[2019-01-21 22:13:38,328] {models.py:1595} INFO - Executing <Task(BashOperator): get_data> on 2019-01-21T00:00:00+00:00
[2019-01-21 22:13:38,328] {base_task_runner.py:118} INFO - Running: ['bash', '-c', 'airflow run seashells get_data 2019-01-21T00:00:00+00:00 --job_id 6 --raw -sd DAGS_FOLDER/tom_test.py --cfg_path /tmp/tmp8gbvqkzz']
[2019-01-21 22:13:38,832] {base_task_runner.py:101} INFO - Job 6: Subtask get_data [2019-01-21 22:13:38,831] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-01-21 22:13:39,141] {base_task_runner.py:101} INFO - Job 6: Subtask get_data [2019-01-21 22:13:39,141] {models.py:271} INFO - Filling up the DagBag from /home/brute/Dropbox/Writing/Blog/andana/assets/notebooks/dags/tom_test.py
[2019-01-21 22:13:39,221] {base_task_runner.py:101} INFO - Job 6: Subtask get_data [2019-01-21 22:13:39,221] {cli.py:484} INFO - Running <TaskInstance: seashells.get_data 2019-01-21T00:00:00+00:00 [running]> on host localhost.localdomain
[2019-01-21 22:13:39,231] {bash_operator.py:74} INFO - Tmp dir root location: 
 /tmp
[2019-01-21 22:13:39,232] {bash_operator.py:87} INFO - Temporary script location: /tmp/airflowtmppa5z9hlc/get_datamjzoug5s
[2019-01-21 22:13:39,232] {bash_operator.py:97} INFO - Running command: cd /home/brute/Dropbox/Writing/Blog/andana/assets/misc && wget http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data
[2019-01-21 22:13:39,235] {bash_operator.py:106} INFO - Output:
[2019-01-21 22:13:39,383] {bash_operator.py:110} INFO - --2019-01-21 22:13:39--  http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data
[2019-01-21 22:13:39,438] {bash_operator.py:110} INFO - Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249
[2019-01-21 22:13:39,490] {bash_operator.py:110} INFO - Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:80... connected.
[2019-01-21 22:13:39,554] {bash_operator.py:110} INFO - HTTP request sent, awaiting response... 200 OK
[2019-01-21 22:13:39,555] {bash_operator.py:110} INFO - Length: 30286 (30K) [text/plain]
[2019-01-21 22:13:39,555] {bash_operator.py:110} INFO - Saving to: ‘auto-mpg.data’
[2019-01-21 22:13:39,555] {bash_operator.py:110} INFO - 
[2019-01-21 22:13:39,612] {bash_operator.py:110} INFO -      0K .......... .......... .........                       100%  512K=0.06s
[2019-01-21 22:13:39,612] {bash_operator.py:110} INFO - 
[2019-01-21 22:13:39,613] {bash_operator.py:110} INFO - 2019-01-21 22:13:39 (512 KB/s) - ‘auto-mpg.data’ saved [30286/30286]
[2019-01-21 22:13:39,613] {bash_operator.py:110} INFO - 
[2019-01-21 22:13:39,613] {bash_operator.py:114} INFO - Command exited with return code 0
[2019-01-21 22:13:43,102] {logging_mixin.py:95} INFO - [2019-01-21 22:13:43,101] {jobs.py:2627} INFO - Task exited with return code 0
